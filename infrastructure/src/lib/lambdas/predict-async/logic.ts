import { processAsynchronously } from 'lib/utils/ai/bedrock-utils';
import { addMessage, updateThreadStatus } from 'lib/utils/dynamodb';
import { extractSentenceInfo } from 'lib/utils/text/sentence-extractor';
import { createTimeoutTask } from 'lib/utils/time/timeout-task';
import { synthesizeSpeechAndUploadAudio } from 'lib/utils/voice';
import { EventType, MessageSystemStatus } from '../../utils/types';
import { S3_BUCKET, SPEECH_SECRET, TABLE_NAME } from './config';
import { sendChunk } from './queries';

/**
 * Processes a single event.
 * @param userId {string} The user ID.
 * @param threadId {string} The thread ID.
 * @param userPrompt {string} The full prompt to process. This includes the thread's system prompt, message history, user's prompt, and start of the AI's response.
 * @param eventTimeout {number} The timeout for the event.
 * @returns {Promise<{ statusCode: number; message: string }>} The result of the event.
 */
export async function processSingleEvent({
  userId,
  threadId,
  history,
  query,
  eventTimeout,
  persona,
  responseOptions
}: EventType) {
  // Add the user's message to the conversation history.
  // This allows the AI model to use the user's message as context for generating the response.
  const updatedHistory = [...history, { sender: 'User', message: query }];
  const formattedHistory = updatedHistory
    .map(({ sender, message }) => `${sender}: ${message}`)
    .join('\n\n')
    .trim();
  const completeQuery = `${formattedHistory}\nAssistant:`;

  // The generated text and audio clips are used to store the response generated by the AI model
  // and voice synthesis service.
  let generatedText = '';
  let generatedTextLastSentence = '';
  let generatedAudioClips: string[] = [];

  // The timeout task is used to ensure that the event does not run indefinitely
  // or for longer than the specified timeout.
  const timeoutTask = createTimeoutTask(eventTimeout);

  // The processing task is used to process the prompt asynchronously
  // and stream the response to the user as it is generated.
  const processingTask = new Promise(async (resolve) => {
    console.log(`Processing prompt: ${completeQuery}`);

    await Promise.all([
      addMessage({
        id: userId,
        threadId,
        message: query,
        sender: 'User',
        tableName: TABLE_NAME
      }),

      processAsynchronously({
        query,
        completeQuery,
        promptTemplate: persona.prompt,
        model: persona.model,
        knowledgeBaseId: persona.knowledgeBaseId,
        callback: async (chunk) => {
          try {
            generatedText += chunk;
            generatedTextLastSentence += chunk;

            const sentenceResult = extractSentenceInfo(
              generatedTextLastSentence
            );

            console.log(`Received Text Chunk: ${chunk}`);
            await sendChunk({
              userId,
              threadId,
              chunk: generatedText,
              chunkType: 'text'
            });

            if (responseOptions.includeAudio && sentenceResult.hasComplete) {
              // If the sentence is complete, we synthesize the audio and send it to the user.
              // We'll capture the remaining text and use it to generate the next audio clip.
              console.log(`Received Audio Chunk: ${generatedText}`);
              generatedTextLastSentence = sentenceResult.remaining;
              const audio = await synthesizeSpeechAndUploadAudio({
                voice: persona.voice,
                audioText: sentenceResult.sentence,
                keyPrefix: `audio/${userId}/${threadId}/`,
                bucket: S3_BUCKET,
                speechSecretArn: SPEECH_SECRET
              });
              generatedAudioClips.push(audio);

              await sendChunk({
                userId,
                threadId,
                chunk: audio,
                chunkType: 'audio'
              });
            }
          } catch (err) {
            console.error('An error occurred while processing the chunk:', err);
            await sendChunk({
              userId,
              threadId,
              chunk: 'An error occurred while processing the prompt.',
              chunkType: 'error'
            });
          }
        }
      })
    ]);

    resolve({
      statusCode: 200,
      message: 'Event processed successfully.'
    });
  });

  // Here, we race the processing task and the timeout task.
  // This is done so that time is left for error handling if the processing task fails,
  // that is relayed to the client.
  const res = await Promise.race([processingTask, timeoutTask]);

  await Promise.all([
    addMessage({
      id: userId,
      threadId,
      message: generatedText,
      audioClips: generatedAudioClips,
      sender: 'Assistant',
      tableName: TABLE_NAME
    }),
    updateThreadStatus({
      userId: userId,
      threadId,
      status: MessageSystemStatus.COMPLETE,
      tableName: TABLE_NAME
    }),
    sendChunk({
      userId,
      threadId,
      status: MessageSystemStatus.COMPLETE,
      chunkType: 'status'
    })
  ]);

  return res;
}
